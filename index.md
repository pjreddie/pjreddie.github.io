---
title: "Joseph Redmon - Survival Strategies for the Robot Rebellion"
layout: default
permalink: /
---
<style>
#ponies img, #external img{
display:inline;
}
</style>

<div class=top>
<h1 class="header">Joseph Chet Redmon</h1>
<div class='green bar'></div>
<div class='blue bar'></div>
</div>

# Interested in AI for the Environment??

I'm working on the OlmoEarth team at Ai2 building state-of-the-art AI for environmental and humanitarian groups.

Platform: [OlmoEarth Platform](https://olmoearth.allenai.org)

Project blog: [OlmoEarth](https://allenai.org/olmoearth)

Technical blog: [OlmoEarth Models](https://allenai.org/blog/olmoearth-models)

Tech report: [OlmoEarth](/static/papers/OlmoEarth.pdf)

Github: [olmoearth_pretrain](https://github.com/allenai/olmoearth_pretrain)

# Welcome to my website!

I am a research scientist at [Ai2](https://allenai.org/) working on [machine learning for the environment](https://allenai.org/olmoearth).

I was a graduate student advised by [Ali Farhadi](https://homes.cs.washington.edu/~ali/index.html). I work on computer vision.

I maintain the [Darknet Neural Network Framework](https://pjreddie.com/darknet/), a primer on [tactics in Coq](https://pjreddie.com/coq-tactics/), occasionally work on [research](https://pjreddie.com/), and try to stay off [twitter](https://twitter.com/pjreddie). 

Outside of computer science, I enjoy skiing, hiking, rock climbing, and playing with my Alaskan malamute puppy, Kelp!

# Talks and teaching

[The Ancient Secrets of Computer Vision](https://pjreddie.com/courses/computer-vision/) - University of Washington, Spring 2018

[Computers can see. Now what?](https://www.youtube.com/watch?v=XS2UWYuh5u0) - TEDxGateway in Mumbai, India

[How computers learn to recognize objects instantly](https://www.ted.com/talks/joseph_redmon_how_a_computer_learns_to_recognize_objects_instantly/discussion?language=en) - TED2017 in Vancouver, Canada

# Publications 

<div class="paper">
<h4>OlmoEarth</h4>
<a class="button" href="/static/papers/OlmoEarth.pdf">PDF</a>
<p class="byline">OlmoEarth Team, Yawen Zhang, Gabriel Tseng, Joseph Redmon, Henry Herzog, Favyen Bastani, Et al.</p>
<p class="code desc">Tech Report</p>
<div class="break"></div>
</div>
<div class="paper">
<h4>Who Let The Dogs Out? Modeling Dog Behavior From Visual Data</h4>
<a class="button" href="/static/papers/1803.10827.pdf">PDF</a>
<a class="button" href="https://arxiv.org/abs/1803.10827">arXiv</a>
<p class="byline">Kiana Ehsani, Hessam Bagherinezhad, Joseph Redmon, Roozbeh Mottaghi, Ali Farhadi</p>
<p class="code desc">CVPR 2018</p>
<div class="break"></div>
</div>
<div class="paper">
<h4>YOLOv3: An Incremental Improvement</h4>
<a class="button" href="/static/papers/YOLOv3.pdf">PDF</a>
<a class="button" href="https://arxiv.org/abs/1804.02767">arXiv</a>
<p class="byline">Joseph Redmon, Ali Farhadi</p>
<p class="code desc">Tech report</p>
<div class="break"></div>
</div>
<div class="paper">
<h4>IQA: Visual Question Answering in Interactive Environments</h4>
<a class="button" href="/static/papers/IQA.pdf">PDF</a>
<a class="button" href="https://arxiv.org/abs/1712.03316">arXiv</a>
<p class="byline">Daniel Gordon, Aniruddha Kembhavi, Mohammad Rastegari, Joseph Redmon, Dieter Fox, Ali Farhadi</p>
<p class="code desc">CVPR 2018</p>
<div class="break"></div>
</div>
<div class="paper">
<h4>YOLO9000: Better, Faster, Stronger</h4>
<a class="button" href="/static/papers/YOLO9000.pdf">PDF</a>
<a class="button" href="https://arxiv.org/abs/1612.08242">arXiv</a>
<a class="button" href="/publications/yolo9000/">Reviews</a>
<a class="button" href="https://docs.google.com/presentation/d/14qBAiyhMOFl_wZW4dA1CkixgXwf0zKGbpw_0oHK8yEM/edit?usp=sharing">Slides</a>
<p class="byline">Joseph Redmon, Ali Farhadi</p>
<p class="code desc">CVPR 2017, Best Paper Honorable Mention</p>
<div class="break"></div>
</div>
<div class="paper">
<h4>XNOR-Net: ImageNet Classification Using Binary Convolutional Neural Networks</h4>
<a class="button" href="/static/papers/xnor.pdf">PDF</a>
<a class="button" href="http://arxiv.org/abs/1603.05279">arXiv</a>
<a class="button" href="/publications/xnor/">Reviews</a>
<a class="button" href="http://pjreddie.com/static/XNOR_ECCV2.pdf">Slides</a>
<a class="button" href="http://videolectures.net/eccv2016_rastegari_neural_networks/">Talk</a>
<p class="byline">Mohammad Rastegari, Vicente Ordonez, Joseph Redmon, and Ali Farhadi</p>
<p class="code desc">ECCV 2016</p>
<div class="break"></div>
</div>
<div class="paper">
<h4>You Only Look Once: Unified, Real-Time Object Detection</h4>
<a class="button" href="/static/papers/yolo_1.pdf">PDF</a>
<a class="button" href="http://arxiv.org/abs/1506.02640">arXiv</a>
<a class="button" href="/publications/yolo/">Reviews</a>
<a class="button" href="https://docs.google.com/presentation/d/1kAa7NOamBt4calBU9iHgT8a86RRHz9Yz2oh4-GTdX6M/edit?usp=sharing">Slides</a>
<a class="button" href="https://www.youtube.com/watch?v=NM6lrxy0bxs">Talk</a>
<p class="byline">Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi</p>
<p class="code desc">CVPR 2016, OpenCV People's Choice Award</p>
<div class="break"></div>
</div>
<div class="paper">
<h4>Real-Time Grasp Detection Using Convolutional Neural Networks</h4>
<a class="button" href="/static/papers/grasp_detection_1.pdf">PDF</a>
<a class="button" href="http://arxiv.org/abs/1412.3128">arXiv</a>
<a class="button" href="/publications/grasp-detection/">Reviews</a>
<a class="button" href="https://docs.google.com/presentation/d/1Zc9-iR1eVz-zysinwb7bzLGC2no2ZiaD897_14dGbhw/edit?usp=sharing">Slides</a>
<p class="byline">Joseph Redmon and Anelia Angelova</p>
<p class="code desc">ICRA 2015</p>
<div class="break"></div>
</div>

# What people are saying

<blockquote>
... Either The Least Or Most Employable Person Ever
<footer>- The Huffington Post</footer>
</blockquote>
<blockquote>
He knows how to do the internet.
<footer>- Lauren Rosenthal, former intern at the Pittsburgh Post-Gazette</footer>
</blockquote>
<blockquote>
I think the little pony resume is probably not the right choice for grad school.
<footer>- Daniel Scharstein, inventor of the digital sundial</footer>
</blockquote>

# I've worked with

<div id=ponies>
<a target=_blank href="http://uwplse.org/" ><img src="/static/img/plse.png" /></a>
<a target=_blank href="http://www.zerocater.com" ><img src="/static/img/ZeroCater.png" /></a>
<a target=_blank href="http://research.google.com/" ><img src="/static/img/gpony.png" /></a>
<a target=_blank href="http://kucb.org"><img src="/static/img/KUCB.png" /></a>
<a target=_blank href="http://www.ibm.com" ><img src="/static/img/IBM.png" /></a>
<a target=_blank href="http://www.nist.gov" ><img src="/static/img/NIST.png" /></a>
</div>

# Find me
<div id=external>
<a target=_blank href="https://scholar.google.com/citations?user=TDk_NfkAAAAJ" ><img src="/static/img/gscholar.png" /></a>
<a target=_blank href="https://github.com/pjreddie" ><img src="/static/img/github.png" /></a>
<a target=_blank href="https://bsky.app/profile/pjreddie.bsky.social"><img src="/static/img/twitter.png" /></a>
<a target=_blank href="https://www.kaggle.com/users/16295/pjreddie"><img src="/static/img/kaggle.png" /></a>
</div>
